# Ontology
This is the Github repository for the User-Driven eXplainable Artificial Intelligence (UDXAI) ontology.

ABSTRACT:

Artificial intelligence has a significant impact on key decision-making processes. Explainable artificial intelligence is therefore essential to increase acceptance and trust in these decisions. This thesis investigates people's preferences for explanations of AI decisions. To gain insight into these preferences, a survey is conducted. The results show that there are differences between people with various prerequisites in terms of expertise and attitudes towards artificial intelligence. Experts tend to require more problem-specific explanations and prefer detailed insights, while less technical affine people prefer simple explanations to more complex ones. To facilitate the easy exchange of existing and future knowledge on this topic, an ontology and respective knowledge graph are developed in the course of the thesis. The User-Driven eXplainable Artificial Intelligence (UDXAI) ontology links different machine learning algorithms and explainable artificial intelligence approaches along with their properties with the data from the survey and general theories of explanation building.
